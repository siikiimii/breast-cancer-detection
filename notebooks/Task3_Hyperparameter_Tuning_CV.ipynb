{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4c00b8d",
   "metadata": {},
   "source": [
    "# Task 3: Hyperparameter Tuning and Cross-Validation\n",
    "\n",
    "This notebook performs hyperparameter tuning and k-fold cross-validation for SVM and MLP models using the processed WDBC dataset.\n",
    "Steps include:\n",
    "- Loading processed data\n",
    "- Train/test split\n",
    "- Applying k-fold cross-validation\n",
    "- Hyperparameter tuning using GridSearchCV\n",
    "- Evaluating tuned models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13cc741",
   "metadata": {},
   "source": [
    "## 1. Load Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baaab4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X_scaled = np.load('X_scaled.npy')\n",
    "y = np.load('y.npy')\n",
    "print('Features shape:', X_scaled.shape)\n",
    "print('Labels shape:', y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7ac078",
   "metadata": {},
   "source": [
    "## 2. Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374d12e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, stratify=y, random_state=42)\n",
    "print('Train shape:', X_train.shape, 'Test shape:', X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b9381a",
   "metadata": {},
   "source": [
    "## 3. Apply k-Fold Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69bcc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Example: 5-fold CV for SVM\n",
    "svm_model = SVC(kernel='linear', probability=True)\n",
    "cv_scores_svm = cross_val_score(svm_model, X_train, y_train, cv=5)\n",
    "print('SVM CV Scores:', cv_scores_svm)\n",
    "print('SVM Mean CV Score:', cv_scores_svm.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7298a7c5",
   "metadata": {},
   "source": [
    "## 4. Hyperparameter Tuning using GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a08aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# SVM parameter grid\n",
    "svm_params = {\n",
    "    'kernel': ['linear', 'rbf'],\n",
    "    'C': [0.1, 1, 10],\n",
    "    'gamma': ['scale', 'auto']\n",
    "}\n",
    "\n",
    "svm_grid = GridSearchCV(SVC(probability=True), svm_params, cv=5, scoring='accuracy')\n",
    "svm_grid.fit(X_train, y_train)\n",
    "print('Best SVM Params:', svm_grid.best_params_)\n",
    "print('Best SVM CV Score:', svm_grid.best_score_)\n",
    "\n",
    "# MLP parameter grid\n",
    "mlp_params = {\n",
    "    'hidden_layer_sizes': [(100,), (500,), (500,500)],\n",
    "    'activation': ['relu', 'tanh'],\n",
    "    'solver': ['adam'],\n",
    "    'max_iter': [300]\n",
    "}\n",
    "\n",
    "mlp_grid = GridSearchCV(MLPClassifier(random_state=42), mlp_params, cv=5, scoring='accuracy')\n",
    "mlp_grid.fit(X_train, y_train)\n",
    "print('Best MLP Params:', mlp_grid.best_params_)\n",
    "print('Best MLP CV Score:', mlp_grid.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697ae97e",
   "metadata": {},
   "source": [
    "## 5. Evaluate Tuned Models on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ff7952",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Evaluate SVM\n",
    "best_svm = svm_grid.best_estimator_\n",
    "y_pred_svm = best_svm.predict(X_test)\n",
    "print('Tuned SVM Accuracy:', accuracy_score(y_test, y_pred_svm))\n",
    "print('Classification Report:\n",
    "', classification_report(y_test, y_pred_svm))\n",
    "cm_svm = confusion_matrix(y_test, y_pred_svm)\n",
    "sns.heatmap(cm_svm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Tuned SVM Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# ROC Curve for SVM\n",
    "y_prob_svm = best_svm.predict_proba(X_test)[:,1]\n",
    "fpr, tpr, _ = roc_curve(y_test, y_prob_svm)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.plot(fpr, tpr, label=f'SVM (AUC = {roc_auc:.2f})')\n",
    "plt.plot([0,1],[0,1],'--',color='gray')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('SVM ROC Curve')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Evaluate MLP\n",
    "best_mlp = mlp_grid.best_estimator_\n",
    "y_pred_mlp = best_mlp.predict(X_test)\n",
    "print('Tuned MLP Accuracy:', accuracy_score(y_test, y_pred_mlp))\n",
    "print('Classification Report:\n",
    "', classification_report(y_test, y_pred_mlp))\n",
    "cm_mlp = confusion_matrix(y_test, y_pred_mlp)\n",
    "sns.heatmap(cm_mlp, annot=True, fmt='d', cmap='Greens')\n",
    "plt.title('Tuned MLP Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# ROC Curve for MLP\n",
    "y_prob_mlp = best_mlp.predict_proba(X_test)[:,1]\n",
    "fpr_mlp, tpr_mlp, _ = roc_curve(y_test, y_prob_mlp)\n",
    "roc_auc_mlp = auc(fpr_mlp, tpr_mlp)\n",
    "plt.plot(fpr_mlp, tpr_mlp, label=f'MLP (AUC = {roc_auc_mlp:.2f})')\n",
    "plt.plot([0,1],[0,1],'--',color='gray')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('MLP ROC Curve')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb818032",
   "metadata": {},
   "source": [
    "## 6. Save Tuned Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab7503e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "joblib.dump(best_svm, 'best_svm_model.pkl')\n",
    "joblib.dump(best_mlp, 'best_mlp_model.pkl')\n",
    "print('Tuned models saved: best_svm_model.pkl, best_mlp_model.pkl')"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
